{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_week2_seminar_vi.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iponamareva/RL_course/blob/main/RL_week2_seminar_vi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTYTl0u1QAAE"
      },
      "source": [
        "### Markov decision process\n",
        "\n",
        "This week's methods are all built to solve __M__arkov __D__ecision __P__rocesses. In the broadest sense, an MDP is defined by how it changes states and how rewards are computed.\n",
        "\n",
        "State transition is defined by $P(s' |s,a)$ - how likely are you to end at state $s'$ if you take action $a$ from state $s$. Now there's more than one way to define rewards, but we'll use $r(s,a,s')$ function for convenience.\n",
        "\n",
        "_This notebook is inspired by the awesome_ [CS294](https://github.com/berkeleydeeprlcourse/homework/blob/36a0b58261acde756abd55306fbe63df226bf62b/hw2/HW2.ipynb) _by Berkeley_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XbyMB2VQAAG"
      },
      "source": [
        "For starters, let's define a simple MDP from this picture:\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ad/Markov_Decision_Process.svg\" width=\"400px\" alt=\"Diagram by Waldoalvarez via Wikimedia Commons, CC BY-SA 4.0\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo3PqTUEQAAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b883215-1975-4919-b486-ffc43a08f716"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week02_value_based/mdp.py\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 155219 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEyVTn4gQAAJ"
      },
      "source": [
        "transition_probs = {\n",
        "    's0': {\n",
        "        'a0': {'s0': 0.5, 's2': 0.5},\n",
        "        'a1': {'s2': 1}\n",
        "    },\n",
        "    's1': {\n",
        "        'a0': {'s0': 0.7, 's1': 0.1, 's2': 0.2},\n",
        "        'a1': {'s1': 0.95, 's2': 0.05}\n",
        "    },\n",
        "    's2': {\n",
        "        'a0': {'s0': 0.4, 's2': 0.6},\n",
        "        'a1': {'s0': 0.3, 's1': 0.3, 's2': 0.4}\n",
        "    }\n",
        "}\n",
        "rewards = {\n",
        "    's1': {'a0': {'s0': +5}},\n",
        "    's2': {'a1': {'s0': -1}}\n",
        "}\n",
        "\n",
        "from mdp import MDP\n",
        "mdp = MDP(transition_probs, rewards, initial_state='s0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCLWMTfVQAAK"
      },
      "source": [
        "We can now use MDP just as any other gym environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_X80-dzQAAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3d4719-2d01-4095-8585-834397b33500"
      },
      "source": [
        "print('initial state =', mdp.reset())\n",
        "next_state, reward, done, info = mdp.step('a1')\n",
        "print('next_state = %s, reward = %s, done = %s' % (next_state, reward, done))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial state = s0\n",
            "next_state = s2, reward = 0.0, done = False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOtOrpbrQAAM"
      },
      "source": [
        "but it also has other methods that you'll need for Value Iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEgJXJwlQAAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c66b6d-3d5d-4cc5-dcd4-dd12eda3900b"
      },
      "source": [
        "print(\"mdp.get_all_states =\", mdp.get_all_states())\n",
        "print(\"mdp.get_possible_actions('s1') = \", mdp.get_possible_actions('s1'))\n",
        "print(\"mdp.get_next_states('s1', 'a0') = \", mdp.get_next_states('s1', 'a0'))\n",
        "print(\"mdp.get_reward('s1', 'a0', 's0') = \", mdp.get_reward('s1', 'a0', 's0'))\n",
        "print(\"mdp.get_transition_prob('s1', 'a0', 's0') = \", mdp.get_transition_prob('s1', 'a0', 's0'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mdp.get_all_states = ('s0', 's1', 's2')\n",
            "mdp.get_possible_actions('s1') =  ('a0', 'a1')\n",
            "mdp.get_next_states('s1', 'a0') =  {'s0': 0.7, 's1': 0.1, 's2': 0.2}\n",
            "mdp.get_reward('s1', 'a0', 's0') =  5\n",
            "mdp.get_transition_prob('s1', 'a0', 's0') =  0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBv0F4LpRHy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d12ebee-6873-4145-eefa-8fb4c27c86fc"
      },
      "source": [
        "print(\"mdp.get_reward('s1', 'a1', 's0') = \", mdp.get_reward('s1', 'a1', 's0'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mdp.get_reward('s1', 'a1', 's0') =  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ty88ag7QAAO"
      },
      "source": [
        "### Optional: Visualizing MDPs\n",
        "\n",
        "You can also visualize any MDP with the drawing fuction donated by [neer201](https://github.com/neer201).\n",
        "\n",
        "You have to install graphviz for system and for python. \n",
        "\n",
        "1. * For ubuntu just run: `sudo apt-get install graphviz` \n",
        "   * For OSX: `brew install graphviz`\n",
        "2. `pip install graphviz`\n",
        "3. restart the notebook\n",
        "\n",
        "__Note:__ Installing graphviz on some OS (esp. Windows) may be tricky. However, you can ignore this part alltogether and use the standart vizualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrVsf_ooQAAP",
        "outputId": "6be58964-e1e8-448e-a380-eb5fc1d1dd21"
      },
      "source": [
        "from mdp import has_graphviz\n",
        "from IPython.display import display\n",
        "print(\"Graphviz available:\", has_graphviz)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graphviz available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL5_n9NAQAAP",
        "outputId": "64f1c659-425b-48a8-d1cc-323763fdaf2e"
      },
      "source": [
        "if has_graphviz:\n",
        "    from mdp import plot_graph, plot_graph_with_state_values, plot_graph_optimal_strategy_and_state_values\n",
        "    display(plot_graph(mdp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
              " -->\n",
              "<!-- Title: MDP Pages: 1 -->\n",
              "<svg width=\"720pt\" height=\"197pt\"\n",
              " viewBox=\"0.00 0.00 720.00 196.66\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
              "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.704871 0.704871) rotate(0) translate(4 275)\">\n",
              "<title>MDP</title>\n",
              "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-275 1017.46,-275 1017.46,4 -4,4\"/>\n",
              "<!-- s0 -->\n",
              "<g id=\"node1\" class=\"node\"><title>s0</title>\n",
              "<ellipse fill=\"lightgreen\" stroke=\"lightgreen\" cx=\"40\" cy=\"-103\" rx=\"36\" ry=\"36\"/>\n",
              "<ellipse fill=\"none\" stroke=\"lightgreen\" cx=\"40\" cy=\"-103\" rx=\"40\" ry=\"40\"/>\n",
              "<text text-anchor=\"middle\" x=\"40\" y=\"-96.8\" font-family=\"Arial\" font-size=\"24.00\">s0</text>\n",
              "</g>\n",
              "<!-- s0&#45;a0 -->\n",
              "<g id=\"node2\" class=\"node\"><title>s0&#45;a0</title>\n",
              "<ellipse fill=\"lightpink\" stroke=\"lightpink\" cx=\"192.577\" cy=\"-147\" rx=\"27.6545\" ry=\"27.6545\"/>\n",
              "<text text-anchor=\"middle\" x=\"192.577\" y=\"-142\" font-family=\"Arial\" font-size=\"20.00\">a0</text>\n",
              "</g>\n",
              "<!-- s0&#45;&gt;s0&#45;a0 -->\n",
              "<g id=\"edge1\" class=\"edge\"><title>s0&#45;&gt;s0&#45;a0</title>\n",
              "<path fill=\"none\" stroke=\"red\" stroke-width=\"2\" d=\"M79.0735,-111.577C99.3931,-116.435 124.733,-122.944 147,-130 150.338,-131.058 153.79,-132.23 157.227,-133.45\"/>\n",
              "<polygon fill=\"red\" stroke=\"red\" stroke-width=\"2\" points=\"156.171,-136.791 166.764,-136.959 158.588,-130.221 156.171,-136.791\"/>\n",
              "</g>\n",
              "<!-- s0&#45;a1 -->\n",
              "<g id=\"node4\" class=\"node\"><title>s0&#45;a1</title>\n",
              "<ellipse fill=\"lightpink\" stroke=\"lightpink\" cx=\"192.577\" cy=\"-220\" rx=\"27.6545\" ry=\"27.6545\"/>\n",
              "<text text-anchor=\"middle\" x=\"192.577\" y=\"-215\" font-family=\"Arial\" font-size=\"20.00\">a1</text>\n",
              "</g>\n",
              "<!-- s0&#45;&gt;s0&#45;a1 -->\n",
              "<g id=\"edge4\" class=\"edge\"><title>s0&#45;&gt;s0&#45;a1</title>\n",
              "<path fill=\"none\" stroke=\"red\" stroke-width=\"2\" d=\"M66.9211,-132.667C76.2366,-142.537 87.136,-153.237 98,-162 117.05,-177.365 140.454,-191.87 159.091,-202.532\"/>\n",
              "<polygon fill=\"red\" stroke=\"red\" stroke-width=\"2\" points=\"157.386,-205.588 167.817,-207.443 160.82,-199.488 157.386,-205.588\"/>\n",
              "</g>\n",
              "<!-- s0&#45;a0&#45;&gt;s0 -->\n",
              "<g id=\"edge2\" class=\"edge\"><title>s0&#45;a0&#45;&gt;s0</title>\n",
              "<path fill=\"none\" stroke=\"blue\" stroke-dasharray=\"5,2\" d=\"M165.016,-142.698C146.094,-139.302 120.188,-133.974 98,-127 94.1908,-125.803 90.2855,-124.447 86.3924,-123.004\"/>\n",
              "<polygon fill=\"blue\" stroke=\"blue\" points=\"87.3907,-119.637 76.802,-119.277 84.8555,-126.161 87.3907,-119.637\"/>\n",
              "<text text-anchor=\"middle\" x=\"122.5\" y=\"-145.2\" font-family=\"Arial\" font-size=\"16.00\">p = 0.5</text>\n",
              "</g>\n",
              "<!-- s2 -->\n",
              "<g id=\"node3\" class=\"node\"><title>s2</title>\n",
              "<ellipse fill=\"lightgreen\" stroke=\"lightgreen\" cx=\"430.154\" cy=\"-159\" rx=\"36\" ry=\"36\"/>\n",
              "<ellipse fill=\"none\" stroke=\"lightgreen\" cx=\"430.154\" cy=\"-159\" rx=\"40\" ry=\"40\"/>\n",
              "<text text-anchor=\"middle\" x=\"430.154\" y=\"-152.8\" font-family=\"Arial\" font-size=\"24.00\">s2</text>\n",
              "</g>\n",
              "<!-- s0&#45;a0&#45;&gt;s2 -->\n",
              "<g id=\"edge3\" class=\"edge\"><title>s0&#45;a0&#45;&gt;s2</title>\n",
              "<path fill=\"none\" stroke=\"blue\" stroke-dasharray=\"5,2\" d=\"M220.143,-148.353C258.819,-150.323 331.305,-154.016 379.91,-156.492\"/>\n",
              "<polygon fill=\"blue\" stroke=\"blue\" points=\"380.036,-160.002 390.201,-157.016 380.392,-153.011 380.036,-160.002\"/>\n",
              "<text text-anchor=\"middle\" x=\"305.154\" y=\"-162.2\" font-family=\"Arial\" font-size=\"16.00\">p = 0.5</text>\n",
              "</g>\n",
              "<!-- s2&#45;a0 -->\n",
              "<g id=\"node8\" class=\"node\"><title>s2&#45;a0</title>\n",
              "<ellipse fill=\"lightpink\" stroke=\"lightpink\" cx=\"662.731\" cy=\"-129\" rx=\"27.6545\" ry=\"27.6545\"/>\n",
              "<text text-anchor=\"middle\" x=\"662.731\" y=\"-124\" font-family=\"Arial\" font-size=\"20.00\">a0</text>\n",
              "</g>\n",
              "<!-- s2&#45;&gt;s2&#45;a0 -->\n",
              "<g id=\"edge13\" class=\"edge\"><title>s2&#45;&gt;s2&#45;a0</title>\n",
              "<path fill=\"none\" stroke=\"red\" stroke-width=\"2\" d=\"M470.375,-158.605C508.288,-157.576 567.173,-154.264 617.154,-144 620.354,-143.343 623.642,-142.525 626.912,-141.613\"/>\n",
              "<polygon fill=\"red\" stroke=\"red\" stroke-width=\"2\" points=\"628.029,-144.931 636.567,-138.658 625.98,-138.238 628.029,-144.931\"/>\n",
              "</g>\n",
              "<!-- s2&#45;a1 -->\n",
              "<g id=\"node9\" class=\"node\"><title>s2&#45;a1</title>\n",
              "<ellipse fill=\"lightpink\" stroke=\"lightpink\" cx=\"662.731\" cy=\"-56\" rx=\"27.6545\" ry=\"27.6545\"/>\n",
              "<text text-anchor=\"middle\" x=\"662.731\" y=\"-51\" font-family=\"Arial\" font-size=\"20.00\">a1</text>\n",
              "</g>\n",
              "<!-- s2&#45;&gt;s2&#45;a1 -->\n",
              "<g id=\"edge16\" class=\"edge\"><title>s2&#45;&gt;s2&#45;a1</title>\n",
              "<path fill=\"none\" stroke=\"red\" stroke-width=\"2\" d=\"M456.579,-128.48C465.696,-119.154 476.6,-109.623 488.154,-103 531.419,-78.2 588.27,-66.0502 624.91,-60.4193\"/>\n",
              "<polygon fill=\"red\" stroke=\"red\" stroke-width=\"2\" points=\"625.742,-63.8353 635.136,-58.9365 624.738,-56.9077 625.742,-63.8353\"/>\n",
              "</g>\n",
              "<!-- s0&#45;a1&#45;&gt;s2 -->\n",
              "<g id=\"edge5\" class=\"edge\"><title>s0&#45;a1&#45;&gt;s2</title>\n",
              "<path fill=\"none\" stroke=\"blue\" stroke-dasharray=\"5,2\" d=\"M219.837,-214.929C254.866,-207.948 318.68,-194.468 372.154,-179 375.531,-178.023 379,-176.96 382.48,-175.848\"/>\n",
              "<polygon fill=\"blue\" stroke=\"blue\" points=\"383.849,-179.082 392.248,-172.624 381.655,-172.435 383.849,-179.082\"/>\n",
              "<text text-anchor=\"middle\" x=\"305.154\" y=\"-216.2\" font-family=\"Arial\" font-size=\"16.00\">p = 1</text>\n",
              "</g>\n",
              "<!-- s1 -->\n",
              "<g id=\"node5\" class=\"node\"><title>s1</title>\n",
              "<ellipse fill=\"lightgreen\" stroke=\"lightgreen\" cx=\"824.309\" cy=\"-106\" rx=\"36\" ry=\"36\"/>\n",
              "<ellipse fill=\"none\" stroke=\"lightgreen\" cx=\"824.309\" cy=\"-106\" rx=\"40\" ry=\"40\"/>\n",
              "<text text-anchor=\"middle\" x=\"824.309\" y=\"-99.8\" font-family=\"Arial\" font-size=\"24.00\">s1</text>\n",
              "</g>\n",
              "<!-- s1&#45;a0 -->\n",
              "<g id=\"node6\" class=\"node\"><title>s1&#45;a0</title>\n",
              "<ellipse fill=\"lightpink\" stroke=\"lightpink\" cx=\"985.886\" cy=\"-70\" rx=\"27.6545\" ry=\"27.6545\"/>\n",
              "<text text-anchor=\"middle\" x=\"985.886\" y=\"-65\" font-family=\"Arial\" font-size=\"20.00\">a0</text>\n",
              "</g>\n",
              "<!-- s1&#45;&gt;s1&#45;a0 -->\n",
              "<g id=\"edge6\" class=\"edge\"><title>s1&#45;&gt;s1&#45;a0</title>\n",
              "<path fill=\"none\" stroke=\"red\" stroke-width=\"2\" d=\"M863.531,-97.3771C889.464,-91.5267 923.525,-83.8428 948.959,-78.105\"/>\n",
              "<polygon fill=\"red\" stroke=\"red\" stroke-width=\"2\" points=\"949.952,-81.469 958.936,-75.8541 948.411,-74.6406 949.952,-81.469\"/>\n",
              "</g>\n",
              "<!-- s1&#45;a1 -->\n",
              "<g id=\"node7\" class=\"node\"><title>s1&#45;a1</title>\n",
              "<ellipse fill=\"lightpink\" stroke=\"lightpink\" cx=\"985.886\" cy=\"-152\" rx=\"27.6545\" ry=\"27.6545\"/>\n",
              "<text text-anchor=\"middle\" x=\"985.886\" y=\"-147\" font-family=\"Arial\" font-size=\"20.00\">a1</text>\n",
              "</g>\n",
              "<!-- s1&#45;&gt;s1&#45;a1 -->\n",
              "<g id=\"edge10\" class=\"edge\"><title>s1&#45;&gt;s1&#45;a1</title>\n",
              "<path fill=\"none\" stroke=\"red\" stroke-width=\"2\" d=\"M863.837,-113.312C886.389,-118.021 915.267,-124.791 940.309,-133 943.876,-134.169 947.554,-135.508 951.196,-136.922\"/>\n",
              "<polygon fill=\"red\" stroke=\"red\" stroke-width=\"2\" points=\"950.07,-140.243 960.651,-140.775 952.712,-133.76 950.07,-140.243\"/>\n",
              "</g>\n",
              "<!-- s1&#45;a0&#45;&gt;s0 -->\n",
              "<g id=\"edge7\" class=\"edge\"><title>s1&#45;a0&#45;&gt;s0</title>\n",
              "<path fill=\"none\" stroke=\"blue\" stroke-dasharray=\"5,2\" d=\"M963.474,-53.7646C934.012,-33.0859 878.553,-0 825.309,-0 191.577,-0 191.577,-0 191.577,-0 144.186,-0 100.753,-35.1875 72.8408,-64.4291\"/>\n",
              "<polygon fill=\"blue\" stroke=\"blue\" points=\"69.9662,-62.382 65.7381,-72.0966 75.1015,-67.139 69.9662,-62.382\"/>\n",
              "<text text-anchor=\"middle\" x=\"552.654\" y=\"-5.2\" font-family=\"Arial\" font-size=\"16.00\">p = 0.7 &#160;reward =5</text>\n",
              "</g>\n",
              "<!-- s1&#45;a0&#45;&gt;s2 -->\n",
              "<g id=\"edge9\" class=\"edge\"><title>s1&#45;a0&#45;&gt;s2</title>\n",
              "<path fill=\"none\" stroke=\"blue\" stroke-dasharray=\"5,2\" d=\"M970.179,-92.8767C966.041,-99.8269 961.738,-107.589 958.309,-115 948.039,-137.196 960.231,-152.814 940.309,-167 867.594,-218.778 592.763,-183.887 479.943,-166.845\"/>\n",
              "<polygon fill=\"blue\" stroke=\"blue\" points=\"480.276,-163.355 469.862,-165.304 479.218,-170.275 480.276,-163.355\"/>\n",
              "<text text-anchor=\"middle\" x=\"737.309\" y=\"-200.2\" font-family=\"Arial\" font-size=\"16.00\">p = 0.2</text>\n",
              "</g>\n",
              "<!-- s1&#45;a0&#45;&gt;s1 -->\n",
              "<g id=\"edge8\" class=\"edge\"><title>s1&#45;a0&#45;&gt;s1</title>\n",
              "<path fill=\"none\" stroke=\"blue\" stroke-dasharray=\"5,2\" d=\"M959.695,-61.2337C938.465,-55.2571 907.594,-49.9199 882.309,-59 874.67,-61.7432 867.325,-66.0021 860.594,-70.8598\"/>\n",
              "<polygon fill=\"blue\" stroke=\"blue\" points=\"858.135,-68.3406 852.423,-77.264 862.453,-73.8502 858.135,-68.3406\"/>\n",
              "<text text-anchor=\"middle\" x=\"911.309\" y=\"-64.2\" font-family=\"Arial\" font-size=\"16.00\">p = 0.1</text>\n",
              "</g>\n",
              "<!-- s1&#45;a1&#45;&gt;s2 -->\n",
              "<g id=\"edge12\" class=\"edge\"><title>s1&#45;a1&#45;&gt;s2</title>\n",
              "<path fill=\"none\" stroke=\"blue\" stroke-dasharray=\"5,2\" d=\"M969.759,-174.512C962.133,-183.877 952.013,-193.769 940.309,-199 756.84,-280.995 679.08,-261.7 488.154,-199 481.749,-196.897 475.43,-193.811 469.463,-190.272\"/>\n",
              "<polygon fill=\"blue\" stroke=\"blue\" points=\"471.306,-187.296 461.003,-184.823 467.515,-193.181 471.306,-187.296\"/>\n",
              "<text text-anchor=\"middle\" x=\"737.309\" y=\"-258.2\" font-family=\"Arial\" font-size=\"16.00\">p = 0.05</text>\n",
              "</g>\n",
              "<!-- s1&#45;a1&#45;&gt;s1 -->\n",
              "<g id=\"edge11\" class=\"edge\"><title>s1&#45;a1&#45;&gt;s1</title>\n",
              "<path fill=\"none\" stroke=\"blue\" stroke-dasharray=\"5,2\" d=\"M958.394,-147.727C937.471,-144.016 907.674,-137.983 882.309,-130 878.5,-128.801 874.595,-127.444 870.702,-126.001\"/>\n",
              "<polygon fill=\"blue\" stroke=\"blue\" points=\"871.701,-122.634 861.112,-122.273 869.165,-129.158 871.701,-122.634\"/>\n",
              "<text text-anchor=\"middle\" x=\"911.309\" y=\"-150.2\" font-family=\"Arial\" font-size=\"16.00\">p = 0.95</text>\n",
              "</g>\n",
              "<!-- s2&#45;a0&#45;&gt;s0 -->\n",
              "<g id=\"edge14\" class=\"edge\"><title>s2&#45;a0&#45;&gt;s0</title>\n",
              "<path fill=\"none\" stroke=\"blue\" stroke-dasharray=\"5,2\" d=\"M639.021,-114.018C632.261,-110.335 624.651,-106.904 617.154,-105 427.072,-56.7313 190.201,-81.2241 89.7024,-95.3394\"/>\n",
              "<polygon fill=\"blue\" stroke=\"blue\" points=\"88.9547,-91.9108 79.5531,-96.7954 89.9488,-98.8398 88.9547,-91.9108\"/>\n",
              "<text text-anchor=\"middle\" x=\"305.154\" y=\"-86.2\" font-family=\"Arial\" font-size=\"16.00\">p = 0.4</text>\n",
              "</g>\n",
              "<!-- s2&#45;a0&#45;&gt;s1 -->\n",
              "<g id=\"edge15\" class=\"edge\"><title>s2&#45;a0&#45;&gt;s1</title>\n",
              "<path fill=\"none\" stroke=\"blue\" stroke-dasharray=\"5,2\" d=\"M690.082,-125.202C713.025,-121.895 746.878,-117.016 774.717,-113.004\"/>\n",
              "<polygon fill=\"blue\" stroke=\"blue\" points=\"775.272,-116.46 784.67,-111.569 774.273,-109.531 775.272,-116.46\"/>\n",
              "<text text-anchor=\"middle\" x=\"737.309\" y=\"-128.2\" font-family=\"Arial\" font-size=\"16.00\">p = 0.6</text>\n",
              "</g>\n",
              "<!-- s2&#45;a1&#45;&gt;s0 -->\n",
              "<g id=\"edge17\" class=\"edge\"><title>s2&#45;a1&#45;&gt;s0</title>\n",
              "<path fill=\"none\" stroke=\"blue\" stroke-dasharray=\"5,2\" d=\"M634.867,-53.9388C567.736,-49.2213 387.339,-39.2124 238.154,-55 185.836,-60.5367 127.463,-75.9491 87.9054,-87.8304\"/>\n",
              "<polygon fill=\"blue\" stroke=\"blue\" points=\"86.8144,-84.5039 78.2688,-90.7669 88.8548,-91.1999 86.8144,-84.5039\"/>\n",
              "<text text-anchor=\"middle\" x=\"305.154\" y=\"-60.2\" font-family=\"Arial\" font-size=\"16.00\">p = 0.3 &#160;reward =&#45;1</text>\n",
              "</g>\n",
              "<!-- s2&#45;a1&#45;&gt;s2 -->\n",
              "<g id=\"edge19\" class=\"edge\"><title>s2&#45;a1&#45;&gt;s2</title>\n",
              "<path fill=\"none\" stroke=\"blue\" stroke-dasharray=\"5,2\" d=\"M644.001,-76.5595C636.457,-84.0842 627.104,-91.9769 617.154,-97 565.021,-123.32 542.31,-100.144 488.154,-122 482.617,-124.235 477.042,-127.032 471.66,-130.082\"/>\n",
              "<polygon fill=\"blue\" stroke=\"blue\" points=\"469.588,-127.243 462.825,-135.398 473.198,-133.241 469.588,-127.243\"/>\n",
              "<text text-anchor=\"middle\" x=\"552.654\" y=\"-127.2\" font-family=\"Arial\" font-size=\"16.00\">p = 0.4</text>\n",
              "</g>\n",
              "<!-- s2&#45;a1&#45;&gt;s1 -->\n",
              "<g id=\"edge18\" class=\"edge\"><title>s2&#45;a1&#45;&gt;s1</title>\n",
              "<path fill=\"none\" stroke=\"blue\" stroke-dasharray=\"5,2\" d=\"M689.37,-64.0334C712.698,-71.3427 747.719,-82.3157 776.1,-91.2083\"/>\n",
              "<polygon fill=\"blue\" stroke=\"blue\" points=\"775.243,-94.6074 785.832,-94.2575 777.336,-87.9276 775.243,-94.6074\"/>\n",
              "<text text-anchor=\"middle\" x=\"737.309\" y=\"-92.2\" font-family=\"Arial\" font-size=\"16.00\">p = 0.3</text>\n",
              "</g>\n",
              "</g>\n",
              "</svg>\n"
            ],
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f729b9db7b8>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4ixhF6XQAAQ"
      },
      "source": [
        "### Value Iteration\n",
        "\n",
        "Now let's build something to solve this MDP. The simplest algorithm so far is __V__alue __I__teration\n",
        "\n",
        "Here's the pseudo-code for VI:\n",
        "\n",
        "---\n",
        "\n",
        "`1.` Initialize $V^{(0)}(s)=0$, for all $s$\n",
        "\n",
        "`2.` For $i=0, 1, 2, \\dots$\n",
        " \n",
        "`3.` $ \\quad V_{(i+1)}(s) = \\max_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')]$, for all $s$\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JebanI5nQAAR"
      },
      "source": [
        "First, let's write a function to compute the state-action value function $Q^{\\pi}$, defined as follows\n",
        "\n",
        "$$Q_i(s, a) = \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')]$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uJgHQzjQAAR"
      },
      "source": [
        "def get_action_value(mdp, state_values, state, action, gamma):\n",
        "    \"\"\" Computes Q(s,a) as in formula above \"\"\"\n",
        "    Q = 0\n",
        "    for s_1 in list(mdp.get_all_states()):\n",
        "        p, r, gv = mdp.get_transition_prob(state, action, s_1), mdp.get_reward(state, action, s_1), gamma * state_values[s_1]\n",
        "        Q += p * (r + gv)\n",
        "\n",
        "    return Q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If5tQFWcQAAS"
      },
      "source": [
        "import numpy as np\n",
        "test_Vs = {s: i for i, s in enumerate(sorted(mdp.get_all_states()))}\n",
        "assert np.isclose(get_action_value(mdp, test_Vs, 's2', 'a1', 0.9), 0.69)\n",
        "assert np.isclose(get_action_value(mdp, test_Vs, 's1', 'a0', 0.9), 3.95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aQkp1ToQAAT"
      },
      "source": [
        "Using $Q(s,a)$ we can now define the \"next\" V(s) for value iteration.\n",
        " $$V_{(i+1)}(s) = \\max_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')] = \\max_a Q_i(s,a)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16lLQ2jKQAAT"
      },
      "source": [
        "def get_new_state_value(mdp, state_values, state, gamma):\n",
        "    \"\"\" Computes next V(s) as in formula above. Please do not change state_values in process. \"\"\"\n",
        "    if mdp.is_terminal(state):\n",
        "        return 0\n",
        "    m = -9e10\n",
        "    for action in mdp.get_possible_actions(state):\n",
        "        temp = get_action_value(mdp, state_values, state, action, gamma)\n",
        "        if temp > m:\n",
        "            m = temp\n",
        "    return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXJy2EZxQAAU"
      },
      "source": [
        "test_Vs_copy = dict(test_Vs)\n",
        "assert np.isclose(get_new_state_value(mdp, test_Vs, 's0', 0.9), 1.8)\n",
        "assert np.isclose(get_new_state_value(mdp, test_Vs, 's2', 0.9), 1.08)\n",
        "assert np.isclose(get_new_state_value(mdp, {'s0': -1e10, 's1': 0, 's2': -2e10}, 's0', 0.9), -13500000000.0), \\\n",
        "    \"Please ensure that you handle negative Q-values of arbitrary magnitude correctly\"\n",
        "assert test_Vs == test_Vs_copy, \"Please do not change state_values in get_new_state_value\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdABmqYiQAAV"
      },
      "source": [
        "Finally, let's combine everything we wrote into a working value iteration algo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnZG0gkZQAAV"
      },
      "source": [
        "# parameters\n",
        "gamma = 0.9            # discount for MDP\n",
        "num_iter = 100         # maximum iterations, excluding initialization\n",
        "# stop VI if new values are this close to old values (or closer)\n",
        "min_difference = 0.001\n",
        "\n",
        "# initialize V(s)\n",
        "state_values = {s: 0 for s in mdp.get_all_states()}\n",
        "\n",
        "# if has_graphviz:\n",
        "#     display(plot_graph_with_state_values(mdp, state_values))\n",
        "\n",
        "for i in range(num_iter):\n",
        "\n",
        "    # Compute new state values using the functions you defined above.\n",
        "    # It must be a dict {state : float V_new(state)}\n",
        "    new_state_values = {state : get_new_state_value(mdp, state_values, state, gamma) for state in mdp.get_all_states()}\n",
        "\n",
        "    assert isinstance(new_state_values, dict)\n",
        "\n",
        "    # Compute difference\n",
        "    diff = max(abs(new_state_values[s] - state_values[s])\n",
        "               for s in mdp.get_all_states())\n",
        "    print(\"iter %4i   |   diff: %6.5f   |   \" % (i, diff), end=\"\")\n",
        "    print('   '.join(\"V(%s) = %.3f\" % (s, v) for s, v in state_values.items()))\n",
        "    state_values = new_state_values\n",
        "\n",
        "    if diff < min_difference:\n",
        "        print(\"Terminated\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-mkb9tIQAAW"
      },
      "source": [
        "if has_graphviz:\n",
        "    display(plot_graph_with_state_values(mdp, state_values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgLiSKbEQAAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac60c56-efba-4e86-f60b-fa035b644fc7"
      },
      "source": [
        "print(\"Final state values:\", state_values)\n",
        "\n",
        "assert abs(state_values['s0'] - 3.781) < 0.01\n",
        "assert abs(state_values['s1'] - 7.294) < 0.01\n",
        "assert abs(state_values['s2'] - 4.202) < 0.01"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final state values: {'s0': 3.7810348735476405, 's1': 7.294006423867229, 's2': 4.202140275227048}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD_vp2gHQAAW"
      },
      "source": [
        "Now let's use those $V^{*}(s)$ to find optimal actions in each state\n",
        "\n",
        " $$\\pi^*(s) = argmax_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')] = argmax_a Q_i(s,a)$$\n",
        " \n",
        "The only difference vs V(s) is that here we take not max but argmax: find action such with maximum Q(s,a)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wna9Y9EQAAX"
      },
      "source": [
        "def get_optimal_action(mdp, state_values, state, gamma=0.9):\n",
        "    \"\"\" Finds optimal action using formula above. \"\"\"\n",
        "    if mdp.is_terminal(state):\n",
        "        return None\n",
        "    m = 0\n",
        "    a = None\n",
        "\n",
        "    for action in mdp.get_possible_actions(state):\n",
        "        Q = get_action_value(mdp, state_values, state, action, gamma)\n",
        "        if Q > m or a is None:\n",
        "            a = action\n",
        "            m = Q\n",
        "\n",
        "\n",
        "    return a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Faj9tDvtQAAX"
      },
      "source": [
        "assert get_optimal_action(mdp, state_values, 's0', gamma) == 'a1'\n",
        "assert get_optimal_action(mdp, state_values, 's1', gamma) == 'a0'\n",
        "assert get_optimal_action(mdp, state_values, 's2', gamma) == 'a1'\n",
        "\n",
        "assert get_optimal_action(mdp, {'s0': -1e10, 's1': 0, 's2': -2e10}, 's0', 0.9) == 'a0', \\\n",
        "    \"Please ensure that you handle negative Q-values of arbitrary magnitude correctly\"\n",
        "assert get_optimal_action(mdp, {'s0': -2e10, 's1': 0, 's2': -1e10}, 's0', 0.9) == 'a1', \\\n",
        "    \"Please ensure that you handle negative Q-values of arbitrary magnitude correctly\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoQoNKJSQAAX"
      },
      "source": [
        "if has_graphviz:\n",
        "    display(plot_graph_optimal_strategy_and_state_values(mdp, state_values, get_action_value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsmIqqlfQAAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35e72cc-5676-49d6-aa5f-7d73ff63e0af"
      },
      "source": [
        "# Measure agent's average reward\n",
        "\n",
        "s = mdp.reset()\n",
        "rewards = []\n",
        "for _ in range(10000):\n",
        "    s, r, done, _ = mdp.step(get_optimal_action(mdp, state_values, s, gamma))\n",
        "    rewards.append(r)\n",
        "\n",
        "print(\"average reward: \", np.mean(rewards))\n",
        "\n",
        "assert(0.40 < np.mean(rewards) < 0.55)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average reward:  0.4113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqvCrB_kQAAY"
      },
      "source": [
        "### Frozen lake"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eT262YqQAAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c263b2b-f6af-475f-9a4d-7a9aa66f600b"
      },
      "source": [
        "from mdp import FrozenLakeEnv\n",
        "mdp = FrozenLakeEnv(slip_chance=0)\n",
        "\n",
        "mdp.render()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*FFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX6wLFKBQAAZ"
      },
      "source": [
        "def value_iteration(mdp, state_values=None, gamma=0.9, num_iter=1000, min_difference=1e-5):\n",
        "    \"\"\" performs num_iter value iteration steps starting from state_values. Same as before but in a function \"\"\"\n",
        "    state_values = state_values or {s: 0 for s in mdp.get_all_states()}\n",
        "    for i in range(num_iter):\n",
        "\n",
        "        # Compute new state values using the functions you defined above. It must be a dict {state : new_V(state)}\n",
        "        new_state_values = {state : get_new_state_value(mdp, state_values, state, gamma) for state in mdp.get_all_states()}\n",
        "\n",
        "        assert isinstance(new_state_values, dict)\n",
        "\n",
        "        # Compute difference\n",
        "        diff = max(abs(new_state_values[s] - state_values[s])\n",
        "                   for s in mdp.get_all_states())\n",
        "\n",
        "        print(\"iter %4i   |   diff: %6.5f   |   V(start): %.3f \" %\n",
        "              (i, diff, new_state_values[mdp._initial_state]))\n",
        "\n",
        "        state_values = new_state_values\n",
        "        if diff < min_difference:\n",
        "            break\n",
        "\n",
        "    return state_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_MstOUUQAAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ef2f8c-838e-443a-c515-0e3a5c3d894a"
      },
      "source": [
        "state_values = value_iteration(mdp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n",
            "iter    1   |   diff: 0.90000   |   V(start): 0.000 \n",
            "iter    2   |   diff: 0.81000   |   V(start): 0.000 \n",
            "iter    3   |   diff: 0.72900   |   V(start): 0.000 \n",
            "iter    4   |   diff: 0.65610   |   V(start): 0.000 \n",
            "iter    5   |   diff: 0.59049   |   V(start): 0.590 \n",
            "iter    6   |   diff: 0.00000   |   V(start): 0.590 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm-ye7ufQAAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d37bc9c2-cd0e-4e7c-e0af-b1887831d72f"
      },
      "source": [
        "s = mdp.reset()\n",
        "mdp.render()\n",
        "for t in range(100):\n",
        "    a = get_optimal_action(mdp, state_values, s, gamma)\n",
        "    print(a, end='\\n\\n')\n",
        "    s, r, done, _ = mdp.step(a)\n",
        "    mdp.render()\n",
        "    if done:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*FFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "\n",
            "down\n",
            "\n",
            "SFFF\n",
            "*HFH\n",
            "FFFH\n",
            "HFFG\n",
            "\n",
            "down\n",
            "\n",
            "SFFF\n",
            "FHFH\n",
            "*FFH\n",
            "HFFG\n",
            "\n",
            "right\n",
            "\n",
            "SFFF\n",
            "FHFH\n",
            "F*FH\n",
            "HFFG\n",
            "\n",
            "down\n",
            "\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H*FG\n",
            "\n",
            "right\n",
            "\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF*G\n",
            "\n",
            "right\n",
            "\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF*\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmcZr6e2QAAa"
      },
      "source": [
        "### Let's visualize!\n",
        "\n",
        "It's usually interesting to see what your algorithm actually learned under the hood. To do so, we'll plot state value functions and optimal actions at each VI step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRJaKghZQAAa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def draw_policy(mdp, state_values):\n",
        "    plt.figure(figsize=(3, 3))\n",
        "    h, w = mdp.desc.shape\n",
        "    states = sorted(mdp.get_all_states())\n",
        "    V = np.array([state_values[s] for s in states])\n",
        "    Pi = {s: get_optimal_action(mdp, state_values, s, gamma) for s in states}\n",
        "    plt.imshow(V.reshape(w, h), cmap='gray', interpolation='none', clim=(0, 1))\n",
        "    ax = plt.gca()\n",
        "    ax.set_xticks(np.arange(h)-.5)\n",
        "    ax.set_yticks(np.arange(w)-.5)\n",
        "    ax.set_xticklabels([])\n",
        "    ax.set_yticklabels([])\n",
        "    Y, X = np.mgrid[0:4, 0:4]\n",
        "    a2uv = {'left': (-1, 0), 'down': (0, -1), 'right': (1, 0), 'up': (0, 1)}\n",
        "    for y in range(h):\n",
        "        for x in range(w):\n",
        "            plt.text(x, y, str(mdp.desc[y, x].item()),\n",
        "                     color='g', size=12,  verticalalignment='center',\n",
        "                     horizontalalignment='center', fontweight='bold')\n",
        "            a = Pi[y, x]\n",
        "            if a is None:\n",
        "                continue\n",
        "            u, v = a2uv[a]\n",
        "            plt.arrow(x, y, u*.3, -v*.3, color='m',\n",
        "                      head_width=0.1, head_length=0.1)\n",
        "    plt.grid(color='b', lw=2, ls='-')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IihXD7_QAAb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a32bda2-7b49-4de9-b021-71f3034fdefa"
      },
      "source": [
        "state_values = {s: 0 for s in mdp.get_all_states()}\n",
        "\n",
        "for i in range(10):\n",
        "    print(\"after iteration %i\" % i)\n",
        "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
        "    draw_policy(mdp, state_values)\n",
        "# please ignore iter 0 at each step"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after iteration 0\n",
            "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after iteration 1\n",
            "iter    0   |   diff: 0.90000   |   V(start): 0.000 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after iteration 2\n",
            "iter    0   |   diff: 0.81000   |   V(start): 0.000 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after iteration 3\n",
            "iter    0   |   diff: 0.72900   |   V(start): 0.000 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after iteration 4\n",
            "iter    0   |   diff: 0.65610   |   V(start): 0.000 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after iteration 5\n",
            "iter    0   |   diff: 0.59049   |   V(start): 0.590 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after iteration 6\n",
            "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAAC0CAYAAAA9zQYyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANvklEQVR4nO3df2wU553H8fczO+td/1wbm21iIDE1xG7aXEIMJIIkgJJQwkUpF9EKN4e4lDaFtiht2iRtTrqg+NRcq7aKmlYop8vlKk5gqWlRpYijNGmoaBTREojC8TPBofwMtjHG9tpe74/pH4NtjI3ttXd+7MP39Q9+VrPar4ePn52dnXm+yrIshNCF4XUBQmSTBFpoRQIttCKBFlqRQAutmGNtoJR6AnjCHhXWQa3DJQkxtqKio3R2dqqrH1eZnLZTaq61adNXs1pYtqxfvw6ArVsbPa7k2urrVwGwc+cfPK7k2pYufRDw934EeO6552hqahoWaDnkEFqRQAutSKCFViTQQisSaKEVCbTQigRaaEUCLbQigRZakUALrUighVYk0EIrEmihFQm00MqY10M7oSXZwm+7fstHfR/Ra/VSZBRRaVayqngVU82pXpQ0xIbjG2hNtg57/MWbX6QqXOV+QSNY/d5qzsfPD3t80+2bqC6s9qCiobzah54E+pVLr3AmeYaavBqigSjtqXY+THzIpfQlpuJ9oPvdWXgn0bzowLgkUOJhNSO7q+wuKsOVA+OIGfGwmuHc3oeuBzqWjnEmeYZ8lc+TpU+ilH2NdsJKYOGvNUIWRxYzr3jeuLcPHglS/L/FdK3sou/2Phh2+Xn2LYsuY2H5QudfCDBPmRRtLaKvto/uR7rH9ZxM9+FkuR7osAoTUiF6rB5+2PZDavJqmBWcxWdCnyGkQm6XM6pdl3ZxqOfQwHhNdM2o25snTYIfByl9qZRURYrOf+50PNg7mnfwQccHA+P1M9dn/TXMUyZFW4oIHQxBAkgx7kBnug8ny/VAB1SA1SWr2XJxC6eTpzmdPM1bvEWJUcL60vVUBavcLuma9sX2QWxw/OyTz475HEtZGHED44zBlB9NoX1dO72Leh2rcc/FPUPG2Q600WJQ8UwFFhbq8l9m+IMwN9TfMOrzAt8OQOnwfahdoAHqwnU88t+PcDh0mLfXvc07Pe/Qke5ge9d2vlH2DS9KGtFT0adYcGHBwPhCw4VRtw/vDlPwxwLSRhoUxJbHiM+LO1pjQ2MDd6+9G+t2Zw7X0uVp2te1U9xYjOpRGHGDxIwEHU90jP68VBqAZ4xnqJtaR7o07Uh9V3M90CkrxceJj5mZmsn84/MpKSqhSBXxetfrxC1n//MzZkJiVmLcmxttBvl/yie2PEb3P3ZjFfrrM8GEGNC7qJfee3oJ/zlMcWMxiVmJMfeLddyCJCRvSJIudifM4EGgE1aCn178Kb/+0q+ZfWo2vR29vN/7PgC1odxeIiE+P05zXTMEvK7EAYHBYPv52wvXAx1UQe4vuJ8TrSfYM3sPvT29lAXKWBRexNKCpW6Xk306hvlKPv/9PPlQuLJ4JTN/M5PQuRBHNh1xu4QxvVz9stcljGlz3WYAghuDJEl6XM1wXu1DH795CJE5CbTQigRaaEUCLbQigRZakUALrbgeaPOiyfSXpxM6Z1+INP3l6YSPh90uI+cZrxsEfmCfFA78PIDxEwPc+0LOt1wPdKArQOHhwoFx4dFCgm1Bt8vIeeqgQu2zLxZSpxTGHgk0eBDo+Iw4sdoYlrKvc0gWJ+ms63S7jJyXejwFl+cBK2yR+krKo0vN/MWTY+iWf2rBMi3SeWmaH22WI/mJuAmseZY9MYTAelCDC6GywJMoxWfE6Z7VTaowJbPzJKQeT9n/yuw8wLPdcPZrZ1EpJbPzZNwEyc1JKPe6EP/wLNDpfPkEkxXRsTe5nsj8KLSScVs32OtgOUKMl8KyrMzbuimlnlBK7VVK7YUWZ2oTIksynqG3bv2eg+VMXH9TS1cWw5gwe1/v3/++x3Vc25w5d1z+yc/70TahGVqIXCKBFlqRQAutSKCFViTQQisSaKEVCbTQigRaaEUCLbQigRZakUALrUighVYk0EIrEmihFddvwfJ9U8tvA6VAI9C/dHUV8C9AL/AfnlQ1zPKdyznXc27Y442LG6mJ1HhQ0VU82o+e3VOYC00tc8F9n7qP6YXTB8ZleWUeVuM9zwLtdkNGXa24eQVLblzidRm+4Vmgd13axaHYoYGjeKf712VsDvZbJICP3zy2ndjG3tbB+zyfvu1pD6sZgcv70bNA74vtGzL2XaB9cBg6Hrubd0Pz4Nh3gXZ5P3oW6Of/8DyL31nMJ1s/8aqE0Y30YcaHGhob+Px3P09wrk8XvHR5P8ppO6EVCbTQigRaaMX1Y+j+hozl/+XTFQZfGuGxE8BGd8sYy/al2wFo39jucSXX4NF+lBlaaEUCLbQigRZakUALrUighVYk0EIr7jfe/Ngk+tUowdP2V7XRtVHC70jjzUzFvh+j/T77lF3s6zE6VnRgJaQTluuBTkfSqPjgsr4qoUiVp9wuI+cZUcO+UB7shptBpBMWXgR6SpqeRT1YpoWFReLmBInahNtl5LzQ4yEIXB7kQ/5T+Sjl/0XKnebJMXTXo132AvF50PmY9CmcCKPMIPTFEBhgTDMw75bpGTwKdHpKmu77u+mb3Sez8ySEHg+hyhT535XZuZ9nf9ada2RmniyjzCDyZsTrMnxFTtsJrUighVak8abIUdJ4U1wHMp6hd+580cFyJm7p0geB3Ghqefbs8BWP/KKy8sbLP/n/rIk03hTak0ALrUighVYk0EIrEmihFQm00IoEWmhFAi20IoEWWpFAC61IoIVWJNBCKxJooRUJtNCK6/cUrn5vNefj54c9vun2TVQXVrtdzoh839QSmL9lPqe7Tg97fOejO/lcxec8qOgq11vjzbvK7qIyXDkwjphj3OxpAR8C1QyuR+GwXGhq+cBND1BVUjUwLs/36ULyLvEs0Muiy1hYvnD8TzgBwW8FscotUmtTWEssx4OdC00t62vreajqIa/L8A3PAr3j3A4OvH0A4vb4m4e+Oer2qllhKQt1QRH4eQBehdRTKax5zq3ntu3YNv56/q+ogH1jhO96AAJb9m3h3bPvDoxfWPCCh9WM4HppvLmnYw8MHnGw4Vcbxv/kPiAB6rByNNC723fDFS1M/Bjot1rfgtbBse8Cfd003qx5fsghR2LnGCsoHQfzWyYEwKqzDzu4ydkaGxobWFy+mKJfFDn7QpPQ0NhA/b/XU7CgwOtSRuZy483cWRCtEtKr0qSXpB0PsshduRPofEivSXtdhfA5+WJFaMX1GXpz3Wa3XzJjQ5paZnBm0U1/+fJfADi68ajHlVyDNN4UYvIk0EIrEmihFQm00IoEWmhFAj0CK26ROmu3mrPaLdLn/Hf+O9WRInHK/nY1cS5BsiXpcUX+IIEeQe9rvXQ+YveASR1M0bG8g+QRfwXmzJozNN3bBMAn3/mEprubsPqk8aYEegTBJcEhZ+hVmSJQ7dJF2ONU/IVilHl5eeQ0FNxTgMrz/5rOTpNAj8CsMTHnmPbeyYfwhjAq6K+wROojqJBdk8pTTH1uqscV+YME+hrCT4bBABVW5D2c53U5wxghg4qnK8CAgnsLCNWEvC7JF3Ln4iSXmbUmeV/Mw7zT9N3s3C9SH6F7dzcVz1Z4XYpvSKBHUfCMT68xvswIGUx7dZrXZfiKHHIIrUighVak8abIUdJ4U1wHJjBDv+dgOZNh/x650NQyg13uOjUw5/nzzM6VpPGm0J4EWmhFAi20IoEWWpFAC61IoIVWJNBCKxJooRUJtNCKBFpoRQIttCKBFlqRQAutuHsLlke96zLl+x6AQNVLVfzt0t+GPb7/6/u544Y7PKhoBNOAe4AZQD7QDTRjX1J/2JmXlHsKR5ELPQAfvuVhqssGG5ZOLfDJcga3AiuxjwFagGNACDvktyGB9kKmPQAT5xJ0vtFJZFWEQLE7C9OsnbOWFbUrxr39pXcv0XO8h+iqKIbp0BFnEHgYO8wHgG1A/2pqCnDwJnVvAu1y77qJ2npka0Y9ALt+30XLCy20/riVKeunUPa1MseD/er+V9l1YtfA+KVlIy2dP+jkiydp+782mp5t4tM/+rQzwZ4B9N8w/ycGwwz2fRgO3vjkTaD90S57TG+efHPI+LGVj439pABYMYu2X7TR9ss2pv1qGoX3FDpUIbxx7I0h4xUPjW+27jvbx7F1x2j6fhNz35tL3qeyuJjOlb9uf5/HB7CPp/ttzN7LXcmbQLvcu26iXvnsK9zWcBtW/PI9U2P8IfYd7bPfZlNAAMyoSWCKszP0azNe49af3Tr4wGdH3777YLf9g8JeE6/WgTXxYlf8XAK0ASeBD4B/yO5LXU2OoUdhTjOp2lE17u0v/s9Fmv+1meDMINF/i1K4tBClnL03r3RBKfO/Mn/c2x/4wgEuvHGB0iWlVP+4muI7i7Nf1CnsMxoFwL3A77A/FHYggc4lkS9FCM0Okb8g3/EgT9Qtm26hb2MfxXMcCHK/BLAdeBT789KNwGkg4txL9pNAZ5FRYFCw0N/Lh4UqQ4QqXVjY8f+xZ+SF2B8S78A+FPkIOOjcy8oyBi6SZQyyS5YxENqTQAutSKCFViTQQisSaKEVCbTQigRaaEUCLbQigRZakUALrUighVYk0EIrEmihFQm00IoEWmglw+uhVSdw1LlyJq0CaPW6iDFIjdlxs2VZwxYhyfSOlaOWZc3NUkFZp5Ta6+f6QGp0mhxyCK1IoIVWMg30fzpSRfb4vT6QGh2V0YdCIfxODjmEViTQQisSaKEVCbTQigRaaOXvDfHJlPquMXIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after iteration 7\n",
            "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after iteration 8\n",
            "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAAC0CAYAAAA9zQYyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANvklEQVR4nO3df2wU553H8fczO+td/1wbm21iIDE1xG7aXEIMJIIkgJJQwkUpF9EKN4e4lDaFtiht2iRtTrqg+NRcq7aKmlYop8vlKk5gqWlRpYijNGmoaBTREojC8TPBofwMtjHG9tpe74/pH4NtjI3ttXd+7MP39Q9+VrPar4ePn52dnXm+yrIshNCF4XUBQmSTBFpoRQIttCKBFlqRQAutmGNtoJR6AnjCHhXWQa3DJQkxtqKio3R2dqqrH1eZnLZTaq61adNXs1pYtqxfvw6ArVsbPa7k2urrVwGwc+cfPK7k2pYufRDw934EeO6552hqahoWaDnkEFqRQAutSKCFViTQQisSaKEVCbTQigRaaEUCLbQigRZakUALrUighVYk0EIrEmihFQm00MqY10M7oSXZwm+7fstHfR/Ra/VSZBRRaVayqngVU82pXpQ0xIbjG2hNtg57/MWbX6QqXOV+QSNY/d5qzsfPD3t80+2bqC6s9qCiobzah54E+pVLr3AmeYaavBqigSjtqXY+THzIpfQlpuJ9oPvdWXgn0bzowLgkUOJhNSO7q+wuKsOVA+OIGfGwmuHc3oeuBzqWjnEmeYZ8lc+TpU+ilH2NdsJKYOGvNUIWRxYzr3jeuLcPHglS/L/FdK3sou/2Phh2+Xn2LYsuY2H5QudfCDBPmRRtLaKvto/uR7rH9ZxM9+FkuR7osAoTUiF6rB5+2PZDavJqmBWcxWdCnyGkQm6XM6pdl3ZxqOfQwHhNdM2o25snTYIfByl9qZRURYrOf+50PNg7mnfwQccHA+P1M9dn/TXMUyZFW4oIHQxBAkgx7kBnug8ny/VAB1SA1SWr2XJxC6eTpzmdPM1bvEWJUcL60vVUBavcLuma9sX2QWxw/OyTz475HEtZGHED44zBlB9NoX1dO72Leh2rcc/FPUPG2Q600WJQ8UwFFhbq8l9m+IMwN9TfMOrzAt8OQOnwfahdoAHqwnU88t+PcDh0mLfXvc07Pe/Qke5ge9d2vlH2DS9KGtFT0adYcGHBwPhCw4VRtw/vDlPwxwLSRhoUxJbHiM+LO1pjQ2MDd6+9G+t2Zw7X0uVp2te1U9xYjOpRGHGDxIwEHU90jP68VBqAZ4xnqJtaR7o07Uh9V3M90CkrxceJj5mZmsn84/MpKSqhSBXxetfrxC1n//MzZkJiVmLcmxttBvl/yie2PEb3P3ZjFfrrM8GEGNC7qJfee3oJ/zlMcWMxiVmJMfeLddyCJCRvSJIudifM4EGgE1aCn178Kb/+0q+ZfWo2vR29vN/7PgC1odxeIiE+P05zXTMEvK7EAYHBYPv52wvXAx1UQe4vuJ8TrSfYM3sPvT29lAXKWBRexNKCpW6Xk306hvlKPv/9PPlQuLJ4JTN/M5PQuRBHNh1xu4QxvVz9stcljGlz3WYAghuDJEl6XM1wXu1DH795CJE5CbTQigRaaEUCLbQigRZakUALrbgeaPOiyfSXpxM6Z1+INP3l6YSPh90uI+cZrxsEfmCfFA78PIDxEwPc+0LOt1wPdKArQOHhwoFx4dFCgm1Bt8vIeeqgQu2zLxZSpxTGHgk0eBDo+Iw4sdoYlrKvc0gWJ+ms63S7jJyXejwFl+cBK2yR+krKo0vN/MWTY+iWf2rBMi3SeWmaH22WI/mJuAmseZY9MYTAelCDC6GywJMoxWfE6Z7VTaowJbPzJKQeT9n/yuw8wLPdcPZrZ1EpJbPzZNwEyc1JKPe6EP/wLNDpfPkEkxXRsTe5nsj8KLSScVs32OtgOUKMl8KyrMzbuimlnlBK7VVK7YUWZ2oTIksynqG3bv2eg+VMXH9TS1cWw5gwe1/v3/++x3Vc25w5d1z+yc/70TahGVqIXCKBFlqRQAutSKCFViTQQisSaKEVCbTQigRaaEUCLbQigRZakUALrUighVYk0EIrEmihFddvwfJ9U8tvA6VAI9C/dHUV8C9AL/AfnlQ1zPKdyznXc27Y442LG6mJ1HhQ0VU82o+e3VOYC00tc8F9n7qP6YXTB8ZleWUeVuM9zwLtdkNGXa24eQVLblzidRm+4Vmgd13axaHYoYGjeKf712VsDvZbJICP3zy2ndjG3tbB+zyfvu1pD6sZgcv70bNA74vtGzL2XaB9cBg6Hrubd0Pz4Nh3gXZ5P3oW6Of/8DyL31nMJ1s/8aqE0Y30YcaHGhob+Px3P09wrk8XvHR5P8ppO6EVCbTQigRaaMX1Y+j+hozl/+XTFQZfGuGxE8BGd8sYy/al2wFo39jucSXX4NF+lBlaaEUCLbQigRZakUALrUighVYk0EIr7jfe/Ngk+tUowdP2V7XRtVHC70jjzUzFvh+j/T77lF3s6zE6VnRgJaQTluuBTkfSqPjgsr4qoUiVp9wuI+cZUcO+UB7shptBpBMWXgR6SpqeRT1YpoWFReLmBInahNtl5LzQ4yEIXB7kQ/5T+Sjl/0XKnebJMXTXo132AvF50PmY9CmcCKPMIPTFEBhgTDMw75bpGTwKdHpKmu77u+mb3Sez8ySEHg+hyhT535XZuZ9nf9ada2RmniyjzCDyZsTrMnxFTtsJrUighVak8abIUdJ4U1wHMp6hd+580cFyJm7p0geB3Ghqefbs8BWP/KKy8sbLP/n/rIk03hTak0ALrUighVYk0EIrEmihFQm00IoEWmhFAi20IoEWWpFAC61IoIVWJNBCKxJooRUJtNCK6/cUrn5vNefj54c9vun2TVQXVrtdzoh839QSmL9lPqe7Tg97fOejO/lcxec8qOgq11vjzbvK7qIyXDkwjphj3OxpAR8C1QyuR+GwXGhq+cBND1BVUjUwLs/36ULyLvEs0Muiy1hYvnD8TzgBwW8FscotUmtTWEssx4OdC00t62vreajqIa/L8A3PAr3j3A4OvH0A4vb4m4e+Oer2qllhKQt1QRH4eQBehdRTKax5zq3ntu3YNv56/q+ogH1jhO96AAJb9m3h3bPvDoxfWPCCh9WM4HppvLmnYw8MHnGw4Vcbxv/kPiAB6rByNNC723fDFS1M/Bjot1rfgtbBse8Cfd003qx5fsghR2LnGCsoHQfzWyYEwKqzDzu4ydkaGxobWFy+mKJfFDn7QpPQ0NhA/b/XU7CgwOtSRuZy483cWRCtEtKr0qSXpB0PsshduRPofEivSXtdhfA5+WJFaMX1GXpz3Wa3XzJjQ5paZnBm0U1/+fJfADi68ajHlVyDNN4UYvIk0EIrEmihFQm00IoEWmhFAj0CK26ROmu3mrPaLdLn/Hf+O9WRInHK/nY1cS5BsiXpcUX+IIEeQe9rvXQ+YveASR1M0bG8g+QRfwXmzJozNN3bBMAn3/mEprubsPqk8aYEegTBJcEhZ+hVmSJQ7dJF2ONU/IVilHl5eeQ0FNxTgMrz/5rOTpNAj8CsMTHnmPbeyYfwhjAq6K+wROojqJBdk8pTTH1uqscV+YME+hrCT4bBABVW5D2c53U5wxghg4qnK8CAgnsLCNWEvC7JF3Ln4iSXmbUmeV/Mw7zT9N3s3C9SH6F7dzcVz1Z4XYpvSKBHUfCMT68xvswIGUx7dZrXZfiKHHIIrUighVak8abIUdJ4U1wHJjBDv+dgOZNh/x650NQyg13uOjUw5/nzzM6VpPGm0J4EWmhFAi20IoEWWpFAC61IoIVWJNBCKxJooRUJtNCKBFpoRQIttCKBFlqRQAutuHsLlke96zLl+x6AQNVLVfzt0t+GPb7/6/u544Y7PKhoBNOAe4AZQD7QDTRjX1J/2JmXlHsKR5ELPQAfvuVhqssGG5ZOLfDJcga3AiuxjwFagGNACDvktyGB9kKmPQAT5xJ0vtFJZFWEQLE7C9OsnbOWFbUrxr39pXcv0XO8h+iqKIbp0BFnEHgYO8wHgG1A/2pqCnDwJnVvAu1y77qJ2npka0Y9ALt+30XLCy20/riVKeunUPa1MseD/er+V9l1YtfA+KVlIy2dP+jkiydp+782mp5t4tM/+rQzwZ4B9N8w/ycGwwz2fRgO3vjkTaD90S57TG+efHPI+LGVj439pABYMYu2X7TR9ss2pv1qGoX3FDpUIbxx7I0h4xUPjW+27jvbx7F1x2j6fhNz35tL3qeyuJjOlb9uf5/HB7CPp/ttzN7LXcmbQLvcu26iXvnsK9zWcBtW/PI9U2P8IfYd7bPfZlNAAMyoSWCKszP0azNe49af3Tr4wGdH3777YLf9g8JeE6/WgTXxYlf8XAK0ASeBD4B/yO5LXU2OoUdhTjOp2lE17u0v/s9Fmv+1meDMINF/i1K4tBClnL03r3RBKfO/Mn/c2x/4wgEuvHGB0iWlVP+4muI7i7Nf1CnsMxoFwL3A77A/FHYggc4lkS9FCM0Okb8g3/EgT9Qtm26hb2MfxXMcCHK/BLAdeBT789KNwGkg4txL9pNAZ5FRYFCw0N/Lh4UqQ4QqXVjY8f+xZ+SF2B8S78A+FPkIOOjcy8oyBi6SZQyyS5YxENqTQAutSKCFViTQQisSaKEVCbTQigRaaEUCLbQigRZakUALrUighVYk0EIrEmihFQm00IoEWmglw+uhVSdw1LlyJq0CaPW6iDFIjdlxs2VZwxYhyfSOlaOWZc3NUkFZp5Ta6+f6QGp0mhxyCK1IoIVWMg30fzpSRfb4vT6QGh2V0YdCIfxODjmEViTQQisSaKEVCbTQigRaaOXvDfHJlPquMXIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after iteration 9\n",
            "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3s-OsFfQAAb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "fafc707e-feb6-440b-a74e-307ddc278b47"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "mdp = FrozenLakeEnv(map_name='8x8', slip_chance=0.1)\n",
        "state_values = {s: 0 for s in mdp.get_all_states()}\n",
        "\n",
        "for i in range(30):\n",
        "    clear_output(True)\n",
        "    print(\"after iteration %i\" % i)\n",
        "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
        "    draw_policy(mdp, state_values)\n",
        "    sleep(0.5)\n",
        "# please ignore iter 0 at each step"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after iteration 29\n",
            "iter    0   |   diff: 0.00000   |   V(start): 0.198 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "692utkNyQAAc"
      },
      "source": [
        "Massive tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmRoW1ofQAAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d54aeedc-dc3a-434b-8b8e-7b828f45ae24"
      },
      "source": [
        "mdp = FrozenLakeEnv(slip_chance=0)\n",
        "state_values = value_iteration(mdp)\n",
        "\n",
        "total_rewards = []\n",
        "for game_i in range(1000):\n",
        "    s = mdp.reset()\n",
        "    rewards = []\n",
        "    for t in range(100):\n",
        "        s, r, done, _ = mdp.step(\n",
        "            get_optimal_action(mdp, state_values, s, gamma))\n",
        "        rewards.append(r)\n",
        "        if done:\n",
        "            break\n",
        "    total_rewards.append(np.sum(rewards))\n",
        "\n",
        "print(\"average reward: \", np.mean(total_rewards))\n",
        "assert(1.0 <= np.mean(total_rewards) <= 1.0)\n",
        "print(\"Well done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n",
            "iter    1   |   diff: 0.90000   |   V(start): 0.000 \n",
            "iter    2   |   diff: 0.81000   |   V(start): 0.000 \n",
            "iter    3   |   diff: 0.72900   |   V(start): 0.000 \n",
            "iter    4   |   diff: 0.65610   |   V(start): 0.000 \n",
            "iter    5   |   diff: 0.59049   |   V(start): 0.590 \n",
            "iter    6   |   diff: 0.00000   |   V(start): 0.590 \n",
            "average reward:  1.0\n",
            "Well done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ik1EiWmQAAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45769ede-5170-43a9-99bd-846b26c5f0db"
      },
      "source": [
        "# Measure agent's average reward\n",
        "mdp = FrozenLakeEnv(slip_chance=0.1)\n",
        "state_values = value_iteration(mdp)\n",
        "\n",
        "total_rewards = []\n",
        "for game_i in range(1000):\n",
        "    s = mdp.reset()\n",
        "    rewards = []\n",
        "    for t in range(100):\n",
        "        s, r, done, _ = mdp.step(\n",
        "            get_optimal_action(mdp, state_values, s, gamma))\n",
        "        rewards.append(r)\n",
        "        if done:\n",
        "            break\n",
        "    total_rewards.append(np.sum(rewards))\n",
        "\n",
        "print(\"average reward: \", np.mean(total_rewards))\n",
        "assert(0.8 <= np.mean(total_rewards) <= 0.95)\n",
        "print(\"Well done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter    0   |   diff: 0.90000   |   V(start): 0.000 \n",
            "iter    1   |   diff: 0.72900   |   V(start): 0.000 \n",
            "iter    2   |   diff: 0.62330   |   V(start): 0.000 \n",
            "iter    3   |   diff: 0.50487   |   V(start): 0.000 \n",
            "iter    4   |   diff: 0.40894   |   V(start): 0.000 \n",
            "iter    5   |   diff: 0.34868   |   V(start): 0.349 \n",
            "iter    6   |   diff: 0.06529   |   V(start): 0.410 \n",
            "iter    7   |   diff: 0.05832   |   V(start): 0.468 \n",
            "iter    8   |   diff: 0.01139   |   V(start): 0.480 \n",
            "iter    9   |   diff: 0.00764   |   V(start): 0.487 \n",
            "iter   10   |   diff: 0.00164   |   V(start): 0.489 \n",
            "iter   11   |   diff: 0.00094   |   V(start): 0.490 \n",
            "iter   12   |   diff: 0.00022   |   V(start): 0.490 \n",
            "iter   13   |   diff: 0.00011   |   V(start): 0.490 \n",
            "iter   14   |   diff: 0.00003   |   V(start): 0.490 \n",
            "iter   15   |   diff: 0.00001   |   V(start): 0.490 \n",
            "iter   16   |   diff: 0.00000   |   V(start): 0.490 \n",
            "average reward:  0.877\n",
            "Well done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78UiknJVQAAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d782be-8100-4139-c66f-0a0f2e9e6ac7"
      },
      "source": [
        "# Measure agent's average reward\n",
        "mdp = FrozenLakeEnv(slip_chance=0.25)\n",
        "state_values = value_iteration(mdp)\n",
        "\n",
        "total_rewards = []\n",
        "for game_i in range(1000):\n",
        "    s = mdp.reset()\n",
        "    rewards = []\n",
        "    for t in range(100):\n",
        "        s, r, done, _ = mdp.step(\n",
        "            get_optimal_action(mdp, state_values, s, gamma))\n",
        "        rewards.append(r)\n",
        "        if done:\n",
        "            break\n",
        "    total_rewards.append(np.sum(rewards))\n",
        "\n",
        "print(\"average reward: \", np.mean(total_rewards))\n",
        "assert(0.6 <= np.mean(total_rewards) <= 0.7)\n",
        "print(\"Well done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter    0   |   diff: 0.75000   |   V(start): 0.000 \n",
            "iter    1   |   diff: 0.50625   |   V(start): 0.000 \n",
            "iter    2   |   diff: 0.39867   |   V(start): 0.000 \n",
            "iter    3   |   diff: 0.26910   |   V(start): 0.000 \n",
            "iter    4   |   diff: 0.18164   |   V(start): 0.000 \n",
            "iter    5   |   diff: 0.14013   |   V(start): 0.140 \n",
            "iter    6   |   diff: 0.07028   |   V(start): 0.199 \n",
            "iter    7   |   diff: 0.06030   |   V(start): 0.260 \n",
            "iter    8   |   diff: 0.02594   |   V(start): 0.285 \n",
            "iter    9   |   diff: 0.01918   |   V(start): 0.305 \n",
            "iter   10   |   diff: 0.00858   |   V(start): 0.313 \n",
            "iter   11   |   diff: 0.00560   |   V(start): 0.319 \n",
            "iter   12   |   diff: 0.00260   |   V(start): 0.321 \n",
            "iter   13   |   diff: 0.00159   |   V(start): 0.323 \n",
            "iter   14   |   diff: 0.00076   |   V(start): 0.324 \n",
            "iter   15   |   diff: 0.00045   |   V(start): 0.324 \n",
            "iter   16   |   diff: 0.00022   |   V(start): 0.324 \n",
            "iter   17   |   diff: 0.00012   |   V(start): 0.325 \n",
            "iter   18   |   diff: 0.00006   |   V(start): 0.325 \n",
            "iter   19   |   diff: 0.00003   |   V(start): 0.325 \n",
            "iter   20   |   diff: 0.00002   |   V(start): 0.325 \n",
            "iter   21   |   diff: 0.00001   |   V(start): 0.325 \n",
            "average reward:  0.634\n",
            "Well done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYjIJKpLQAAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b916fb-2a3f-41dc-d380-d726e3acfaf6"
      },
      "source": [
        "# Measure agent's average reward\n",
        "mdp = FrozenLakeEnv(slip_chance=0.2, map_name='8x8')\n",
        "state_values = value_iteration(mdp)\n",
        "\n",
        "total_rewards = []\n",
        "for game_i in range(1000):\n",
        "    s = mdp.reset()\n",
        "    rewards = []\n",
        "    for t in range(100):\n",
        "        s, r, done, _ = mdp.step(\n",
        "            get_optimal_action(mdp, state_values, s, gamma))\n",
        "        rewards.append(r)\n",
        "        if done:\n",
        "            break\n",
        "    total_rewards.append(np.sum(rewards))\n",
        "\n",
        "print(\"average reward: \", np.mean(total_rewards))\n",
        "assert(0.6 <= np.mean(total_rewards) <= 0.8)\n",
        "print(\"Well done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter    0   |   diff: 0.80000   |   V(start): 0.000 \n",
            "iter    1   |   diff: 0.57600   |   V(start): 0.000 \n",
            "iter    2   |   diff: 0.41472   |   V(start): 0.000 \n",
            "iter    3   |   diff: 0.29860   |   V(start): 0.000 \n",
            "iter    4   |   diff: 0.24186   |   V(start): 0.000 \n",
            "iter    5   |   diff: 0.19349   |   V(start): 0.000 \n",
            "iter    6   |   diff: 0.15325   |   V(start): 0.000 \n",
            "iter    7   |   diff: 0.12288   |   V(start): 0.000 \n",
            "iter    8   |   diff: 0.09930   |   V(start): 0.000 \n",
            "iter    9   |   diff: 0.08037   |   V(start): 0.000 \n",
            "iter   10   |   diff: 0.06426   |   V(start): 0.000 \n",
            "iter   11   |   diff: 0.05129   |   V(start): 0.000 \n",
            "iter   12   |   diff: 0.04330   |   V(start): 0.000 \n",
            "iter   13   |   diff: 0.03802   |   V(start): 0.033 \n",
            "iter   14   |   diff: 0.03332   |   V(start): 0.058 \n",
            "iter   15   |   diff: 0.02910   |   V(start): 0.087 \n",
            "iter   16   |   diff: 0.01855   |   V(start): 0.106 \n",
            "iter   17   |   diff: 0.01403   |   V(start): 0.120 \n",
            "iter   18   |   diff: 0.00810   |   V(start): 0.128 \n",
            "iter   19   |   diff: 0.00555   |   V(start): 0.133 \n",
            "iter   20   |   diff: 0.00321   |   V(start): 0.137 \n",
            "iter   21   |   diff: 0.00247   |   V(start): 0.138 \n",
            "iter   22   |   diff: 0.00147   |   V(start): 0.139 \n",
            "iter   23   |   diff: 0.00104   |   V(start): 0.140 \n",
            "iter   24   |   diff: 0.00058   |   V(start): 0.140 \n",
            "iter   25   |   diff: 0.00036   |   V(start): 0.141 \n",
            "iter   26   |   diff: 0.00024   |   V(start): 0.141 \n",
            "iter   27   |   diff: 0.00018   |   V(start): 0.141 \n",
            "iter   28   |   diff: 0.00012   |   V(start): 0.141 \n",
            "iter   29   |   diff: 0.00007   |   V(start): 0.141 \n",
            "iter   30   |   diff: 0.00004   |   V(start): 0.141 \n",
            "iter   31   |   diff: 0.00003   |   V(start): 0.141 \n",
            "iter   32   |   diff: 0.00001   |   V(start): 0.141 \n",
            "iter   33   |   diff: 0.00001   |   V(start): 0.141 \n",
            "average reward:  0.729\n",
            "Well done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb-THc74QAAd"
      },
      "source": [
        "# HW Part 1: Value iteration convergence\n",
        "\n",
        "### Find an MDP for which value iteration takes long to converge  (0.5 pts)\n",
        "\n",
        "When we ran value iteration on the small frozen lake problem, the last iteration where an action changed was iteration 6--i.e., value iteration computed the optimal policy at iteration 6. Are there any guarantees regarding how many iterations it'll take value iteration to compute the optimal policy? There are no such guarantees without additional assumptions--we can construct the MDP in such a way that the greedy policy will change after arbitrarily many iterations.\n",
        "\n",
        "Your task: define an MDP with at most 3 states and 2 actions, such that when you run value iteration, the optimal action changes at iteration >= 50. Use discount=0.95. (However, note that the discount doesn't matter here--you can construct an appropriate MDP with any discount.)\n",
        "\n",
        "Note: value function must change at least once after iteration >=50, not necessarily change on every iteration till >=50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDBqBVizQAAd"
      },
      "source": [
        "transition_probs = {\n",
        "    <YOUR CODE>\n",
        "}\n",
        "rewards = {\n",
        "    <YOUR CODE>\n",
        "}\n",
        "\n",
        "from mdp import MDP\n",
        "from numpy import random\n",
        "mdp = MDP(transition_probs, rewards, initial_state=random.choice(tuple(transition_probs.keys())))\n",
        "# Feel free to change the initial_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmFTOUysQAAd"
      },
      "source": [
        "state_values = {s: 0 for s in mdp.get_all_states()}\n",
        "policy = np.array([get_optimal_action(mdp, state_values, state, gamma)\n",
        "                   for state in sorted(mdp.get_all_states())])\n",
        "\n",
        "for i in range(100):\n",
        "    print(\"after iteration %i\" % i)\n",
        "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
        "\n",
        "    new_policy = np.array([get_optimal_action(mdp, state_values, state, gamma)\n",
        "                           for state in sorted(mdp.get_all_states())])\n",
        "\n",
        "    n_changes = (policy != new_policy).sum()\n",
        "    print(\"N actions changed = %i \\n\" % n_changes)\n",
        "    policy = new_policy\n",
        "\n",
        "# please ignore iter 0 at each step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8y3fhMSQAAe"
      },
      "source": [
        "### Value iteration convervence proof (0.5 pts)\n",
        "**Note:** Assume that $\\mathcal{S}, \\mathcal{A}$ are finite.\n",
        "\n",
        "Update of value function in value iteration can be rewritten in a form of Bellman operator:\n",
        "\n",
        "$$(TV)(s) = \\max_{a \\in \\mathcal{A}}\\mathbb{E}\\left[ r_{t+1} + \\gamma V(s_{t+1}) | s_t = s, a_t = a\\right]$$\n",
        "\n",
        "Value iteration algorithm with Bellman operator:\n",
        "\n",
        "---\n",
        "&nbsp;&nbsp; Initialize $V_0$\n",
        "\n",
        "&nbsp;&nbsp; **for** $k = 0,1,2,...$ **do**\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; $V_{k+1} \\leftarrow TV_k$\n",
        "\n",
        "&nbsp;&nbsp;**end for**\n",
        "\n",
        "---\n",
        "\n",
        "In [lecture](https://docs.google.com/presentation/d/1lz2oIUTvd2MHWKEQSH8hquS66oe4MZ_eRvVViZs2uuE/edit#slide=id.g4fd6bae29e_2_4) we established contraction property of bellman operator:\n",
        "\n",
        "$$\n",
        "||TV - TU||_{\\infty} \\le \\gamma ||V - U||_{\\infty}\n",
        "$$\n",
        "\n",
        "For all $V, U$\n",
        "\n",
        "Using contraction property of Bellman operator, Banach fixed-point theorem and Bellman equations prove that value function converges to $V^*$ in value iterateion$\n",
        "\n",
        "*<-- Your proof here -->*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_dgWsbwQAAe"
      },
      "source": [
        "### Bonus. Asynchronious value iteration (2 pts)\n",
        "\n",
        "Consider the following algorithm:\n",
        "\n",
        "---\n",
        "\n",
        "Initialize $V_0$\n",
        "\n",
        "**for** $k = 0,1,2,...$ **do**\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Select some state $s_k \\in \\mathcal{S}$    \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; $V(s_k) := (TV)(s_k)$\n",
        "\n",
        "**end for**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Note that unlike common value iteration, here we update only a single state at a time.\n",
        "\n",
        "**Homework.** Prove the following proposition:\n",
        "\n",
        "If for all $s \\in \\mathcal{S}$, $s$ appears in the sequence $(s_0, s_1, ...)$ infinitely often, then $V$ converges to $V*$\n",
        "\n",
        "*<-- Your proof here -->*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq0yDoT-QAAe"
      },
      "source": [
        "# HW Part 2: Policy iteration\n",
        "\n",
        "## Policy iteration implementateion (2 pts)\n",
        "\n",
        "Let's implement exact policy iteration (PI), which has the following pseudocode:\n",
        "\n",
        "---\n",
        "Initialize $\\pi_0$   `// random or fixed action`\n",
        "\n",
        "For $n=0, 1, 2, \\dots$\n",
        "- Compute the state-value function $V^{\\pi_{n}}$\n",
        "- Using $V^{\\pi_{n}}$, compute the state-action-value function $Q^{\\pi_{n}}$\n",
        "- Compute new policy $\\pi_{n+1}(s) = \\operatorname*{argmax}_a Q^{\\pi_{n}}(s,a)$\n",
        "---\n",
        "\n",
        "Unlike VI, policy iteration has to maintain a policy - chosen actions from all states - and estimate $V^{\\pi_{n}}$ based on this policy. It only changes policy once values converged.\n",
        "\n",
        "\n",
        "Below are a few helpers that you may or may not use in your implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XlakFo9QAAe"
      },
      "source": [
        "transition_probs = {\n",
        "    's0': {\n",
        "        'a0': {'s0': 0.5, 's2': 0.5},\n",
        "        'a1': {'s2': 1}\n",
        "    },\n",
        "    's1': {\n",
        "        'a0': {'s0': 0.7, 's1': 0.1, 's2': 0.2},\n",
        "        'a1': {'s1': 0.95, 's2': 0.05}\n",
        "    },\n",
        "    's2': {\n",
        "        'a0': {'s0': 0.4, 's1': 0.6},\n",
        "        'a1': {'s0': 0.3, 's1': 0.3, 's2': 0.4}\n",
        "    }\n",
        "}\n",
        "rewards = {\n",
        "    's1': {'a0': {'s0': +5}},\n",
        "    's2': {'a1': {'s0': -1}}\n",
        "}\n",
        "\n",
        "from mdp import MDP\n",
        "mdp = MDP(transition_probs, rewards, initial_state='s0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTPoR--8QAAf"
      },
      "source": [
        "Let's write a function called `compute_vpi` that computes the state-value function $V^{\\pi}$ for an arbitrary policy $\\pi$.\n",
        "\n",
        "Unlike VI, this time you must find the exact solution, not just a single iteration.\n",
        "\n",
        "Recall that $V^{\\pi}$ satisfies the following linear equation:\n",
        "$$V^{\\pi}(s) = \\sum_{s'} P(s,\\pi(s),s')[ R(s,\\pi(s),s') + \\gamma V^{\\pi}(s')]$$\n",
        "\n",
        "You'll have to solve a linear system in your code. (Find an exact solution, e.g., with `np.linalg.solve`.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5XQzEnbQAAf"
      },
      "source": [
        "def compute_vpi(mdp, policy, gamma):\n",
        "    \"\"\"\n",
        "    Computes V^pi(s) FOR ALL STATES under given policy.\n",
        "    :param policy: a dict of currently chosen actions {s : a}\n",
        "    :returns: a dict {state : V^pi(state) for all states}\n",
        "    \"\"\"\n",
        "    <YOUR CODE>\n",
        "    return <YOUR CODE>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lo4eD-SQAAf"
      },
      "source": [
        "test_policy = {s: np.random.choice(\n",
        "    mdp.get_possible_actions(s)) for s in mdp.get_all_states()}\n",
        "new_vpi = compute_vpi(mdp, test_policy, gamma)\n",
        "\n",
        "print(new_vpi)\n",
        "\n",
        "assert type(\n",
        "    new_vpi) is dict, \"compute_vpi must return a dict {state : V^pi(state) for all states}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2IQKqpWQAAf"
      },
      "source": [
        "Once we've got new state values, it's time to update our policy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDv3C6GPQAAg"
      },
      "source": [
        "def compute_new_policy(mdp, vpi, gamma):\n",
        "    \"\"\"\n",
        "    Computes new policy as argmax of state values\n",
        "    :param vpi: a dict {state : V^pi(state) for all states}\n",
        "    :returns: a dict {state : optimal action for all states}\n",
        "    \"\"\"\n",
        "    <YOUR CODE>\n",
        "    return <YOUR CODE>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPVRhSWwQAAg"
      },
      "source": [
        "new_policy = compute_new_policy(mdp, new_vpi, gamma)\n",
        "\n",
        "print(new_policy)\n",
        "\n",
        "assert type(\n",
        "    new_policy) is dict, \"compute_new_policy must return a dict {state : optimal action for all states}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u48aBigYQAAg"
      },
      "source": [
        "__Main loop__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea1x5sd_QAAg"
      },
      "source": [
        "def policy_iteration(mdp, policy=None, gamma=0.9, num_iter=1000, min_difference=1e-5):\n",
        "    \"\"\" \n",
        "    Run the policy iteration loop for num_iter iterations or till difference between V(s) is below min_difference.\n",
        "    If policy is not given, initialize it at random.\n",
        "    \"\"\"\n",
        "    <YOUR CODE: a whole lot of it>\n",
        "\n",
        "    return state_values, policy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFDHAWhlQAAg"
      },
      "source": [
        "__Your PI Results__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15rtQaXlQAAg"
      },
      "source": [
        "<YOUR CODE: compare PI and VI on the MDP from bonus 1, then on small & large FrozenLake>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZljieVFQAAh"
      },
      "source": [
        "## Policy iteration convergence (3 pts)\n",
        "\n",
        "**Note:** Assume that $\\mathcal{S}, \\mathcal{A}$ are finite.\n",
        "\n",
        "We can define another Bellman operator:\n",
        "\n",
        "$$(T_{\\pi}V)(s) = \\mathbb{E}_{r, s'|s, a = \\pi(s)}\\left[r + \\gamma V(s')\\right]$$\n",
        "\n",
        "And rewrite policy iteration algorithm in operator form:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Initialize $\\pi_0$\n",
        "\n",
        "**for** $k = 0,1,2,...$ **do**\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Solve $V_k = T_{\\pi_k}V_k$   \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp; Select $\\pi_{k+1}$ s.t. $T_{\\pi_{k+1}}V_k = TV_k$ \n",
        "\n",
        "**end for**\n",
        "\n",
        "---\n",
        "\n",
        "To prove convergence of the algorithm we need to prove two properties: contraction an monotonicity.\n",
        "\n",
        "#### Monotonicity (0.5 pts)\n",
        "\n",
        "For all $V, U$ if $V(s) \\le U(s)$   $\\forall s \\in \\mathcal{S}$ then $(T_\\pi V)(s) \\le (T_\\pi U)(s)$   $\\forall s \\in  \\mathcal{S}$\n",
        "\n",
        "*<-- Your proof here -->*\n",
        "\n",
        "#### Contraction (1 pts)\n",
        "\n",
        "$$\n",
        "||T_\\pi V - T_\\pi U||_{\\infty} \\le \\gamma ||V - U||_{\\infty}\n",
        "$$\n",
        "\n",
        "For all $V, U$\n",
        "\n",
        "*<-- Your proof here -->*\n",
        "\n",
        "#### Convergence (1.5 pts)\n",
        "\n",
        "Prove that there exists iteration $k_0$ such that $\\pi_k = \\pi^*$ for all $k \\ge k_0$\n",
        "\n",
        "*<-- Your proof here -->*"
      ]
    }
  ]
}